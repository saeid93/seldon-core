{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seldon deployment of income classifier and Alibi anchor explainer\n",
    "\n",
    "The objective of this tutorial is to build a \"loan approval\" predictor using the Income classifier dataset to showcase the importance of black-box model explainers, which in this case are built using our open source framework [Alibi](http://github.com/SeldonIO/Alibi). The diagram of this tutorial is as follows:\n",
    "\n",
    "![deploy-overview](https://github.com//SeldonIO/seldon-core/raw/master/examples/explainers/alibi_anchor_tabular/img/deploy-overview.jpg)\n",
    "\n",
    "In this tutorial we will follow the following steps:\n",
    "\n",
    "1) Train a model to predict loan approvals\n",
    "\n",
    "2) Containerise and deploy your model\n",
    "\n",
    "3) Create an explainer to understand predictions\n",
    "\n",
    "4) Containerise and deploy your explainer\n",
    "\n",
    "5) Test the predictions as well as explanations\n",
    "\n",
    "## Before you start\n",
    "Make sure you install the following dependencies, as they are critical for this example to work:\n",
    "\n",
    "* Helm v3.0.0+\n",
    "* A Kubernetes cluster running v1.13 or above (minkube / docker-for-windows work well if enough RAM)\n",
    "* kubectl v1.14+\n",
    "* ksonnet v0.13.1+\n",
    "* kfctl 0.5.1 - Please use this exact version as there are major changes every few months\n",
    "* Python 3.6+\n",
    "* Python DEV requirements (we'll install them below)\n",
    "\n",
    "You can follow this [notebook](../../../notebooks/seldon_core_setup.ipynb) to setup your cluster.\n",
    "\n",
    "Let's get started! ðŸš€ðŸ”¥ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xai==0.0.5\r\n",
      "seldon_core==0.5.1\r\n",
      "alibi==0.3.2\r\n",
      "dill==0.3.1\r\n",
      "scikit-learn==0.20.1\r\n"
     ]
    }
   ],
   "source": [
    "!cat requirements-dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xai==0.0.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/ff/cb5a2d94f4ce159f7abadc92c581749d6f45b027aaf4cc0823e948064b98/xai-0.0.5-py3-none-any.whl (349kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 358kB 961kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting seldon_core==0.5.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/5e/a55ff47468cc11aac0136b84af92a15133947d4dba75774ce439078d60d9/seldon_core-0.5.1-py3-none-any.whl (60kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 3.0MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting alibi==0.3.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/e7/54214fcf84a65339d6c993121da52edea52b56d39e6ec87ad30c755d665a/alibi-0.3.2-py3-none-any.whl (81kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 7.4MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dill==0.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz (151kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 153kB 8.7MB/s eta 0:00:01\n",
      "\u001b[33m  WARNING: Requested dill==0.3.1 from https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz#sha256=d3ddddf2806a7bc9858b20c02dc174396795545e9d62f243b34481fd26eb3e2c (from -r requirements-dev.txt (line 4)), but installing version 0.3.1.dev0\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==0.20.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/3a/0802b78f697ae04ba06f49d0ebc6e872f2c470687c3e61ad8ef523e125c3/scikit_learn-0.20.1-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.4MB 8.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy==1.1.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31.2MB 6.1MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pytz==2018.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 4.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing==2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e8/6777f6624681c8b9701a8a0a5654f3eb56919a01a78e12bf3c73f5a3c714/pyparsing-2.3.0-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 2.8MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six==1.12.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from xai==0.0.5->-r requirements-dev.txt (line 1)) (1.12.0)\n",
      "Collecting kiwisolver==1.0.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/7e/d6cae2f241ba474a2665f24b480bf4e247036d63939dda2bbc4d2ee5069d/kiwisolver-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (89kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 92kB 4.0MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting pandas==0.23.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/a7/12261a51ac2e7be4c698ca27cbe364ca5f16d64999456ee47ea8c7b44417/pandas-0.23.4-cp37-cp37m-manylinux1_x86_64.whl (8.8MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.8MB 8.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib==3.0.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/5377596cb1c035c102396f5934237a046f80da69974026f90bee5db8b7ba/matplotlib-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (12.9MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12.9MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.15.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/39/f73e104d44f19a6203e786d5204532e214443ea2954917b27f3229e7639b/numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9MB 23.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil==2.7.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl (225kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 235kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from xai==0.0.5->-r requirements-dev.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: Flask-OpenTracing<1.2.0,>=1.1.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: grpcio<2.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.25.0)\n",
      "Requirement already satisfied: flatbuffers<2.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.11)\n",
      "Requirement already satisfied: jaeger-client<4.2.0,>=4.1.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (4.1.0)\n",
      "Requirement already satisfied: azure-storage-blob<3.0.0,>=2.0.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (41.4.0)\n",
      "Requirement already satisfied: gunicorn<20.1.0,>=19.9.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (20.0.4)\n",
      "Requirement already satisfied: Flask-cors<4.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (3.0.8)\n",
      "Requirement already satisfied: opentracing<2.3.0,>=2.2.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: pyaml<20.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (19.4.1)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (3.10.0)\n",
      "Requirement already satisfied: Flask<2.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: minio<6.0.0,>=4.0.9 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (5.0.5)\n",
      "Requirement already satisfied: requests<3.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.22.0)\n",
      "Requirement already satisfied: redis<4.0.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (3.3.11)\n",
      "Requirement already satisfied: grpcio-opentracing<1.2.0,>=1.1.4 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.4)\n",
      "Requirement already satisfied: Pillow in /home/alejandro/miniconda3/lib/python3.7/site-packages (from alibi==0.3.2->-r requirements-dev.txt (line 3)) (7.0.0)\n",
      "Collecting scikit-image\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/48/454bf836d302465475e02bc0468b879302145b07a005174c409a5b5869c7/scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 26.5MB 26.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy in /home/alejandro/miniconda3/lib/python3.7/site-packages (from alibi==0.3.2->-r requirements-dev.txt (line 3)) (2.2.3)\n",
      "Collecting beautifulsoup4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112kB 16.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow<2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110.5MB 199kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: thrift in /home/alejandro/miniconda3/lib/python3.7/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (0.13.0)\n",
      "Requirement already satisfied: tornado<6,>=4.3 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (5.1.1)\n",
      "Requirement already satisfied: threadloop<2,>=1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from jaeger-client<4.2.0,>=4.1.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.0.2)\n",
      "Requirement already satisfied: azure-common>=1.1.5 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from azure-storage-blob<3.0.0,>=2.0.1->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.23)\n",
      "Requirement already satisfied: azure-storage-common~=2.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from azure-storage-blob<3.0.0,>=2.0.1->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.1.0)\n",
      "Requirement already satisfied: PyYAML in /home/alejandro/.local/lib/python3.7/site-packages (from pyaml<20.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (3.13)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from Flask<2.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from Flask<2.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.10.3)\n",
      "Requirement already satisfied: click>=5.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from Flask<2.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from Flask<2.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.0)\n",
      "Requirement already satisfied: certifi in /home/alejandro/miniconda3/lib/python3.7/site-packages (from minio<6.0.0,>=4.0.9->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2019.9.11)\n",
      "Requirement already satisfied: urllib3 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from minio<6.0.0,>=4.0.9->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from requests<3.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from requests<3.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.8)\n",
      "Collecting imageio>=2.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting networkx>=2.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6MB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.4MB 5.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (7.3.1)\n",
      "Collecting soupsieve>=1.2\n",
      "  Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.8.0)\n",
      "Requirement already satisfied: gast==0.2.2 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.1.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (3.1.0)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 8.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.33.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.1.0)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 512kB 19.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.11.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (1.0.8)\n",
      "Requirement already satisfied: cryptography in /home/alejandro/miniconda3/lib/python3.7/site-packages (from azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask<2.0.0->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->alibi==0.3.2->-r requirements-dev.txt (line 3)) (4.4.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/alejandro/miniconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.23)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (4.36.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (3.1.1)\n",
      "Requirement already satisfied: h5py in /home/alejandro/miniconda3/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<2.0->alibi==0.3.2->-r requirements-dev.txt (line 3)) (2.10.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (1.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/alejandro/miniconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pycparser in /home/alejandro/miniconda3/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography->azure-storage-common~=2.1->azure-storage-blob<3.0.0,>=2.0.1->seldon_core==0.5.1->-r requirements-dev.txt (line 2)) (2.19)\n",
      "Requirement already satisfied: more-itertools in /home/alejandro/miniconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->alibi==0.3.2->-r requirements-dev.txt (line 3)) (7.2.0)\n",
      "Building wheels for collected packages: dill\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.dev0-cp37-none-any.whl size=78554 sha256=3f80d78a42751f123bdcd71ceab39f7de5f1b42bad0cdce3d5f9f762f8f76097\n",
      "  Stored in directory: /home/alejandro/.cache/pip/wheels/b6/26/8f/152327a2b78a0c2c3166e5d20d331bd4fb1272e810836fed76\n",
      "Successfully built dill\n",
      "\u001b[31mERROR: tensorflow 1.15.2 has requirement numpy<2.0,>=1.16.0, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: creme 0.4.4 has requirement numpy>=1.16.4, but you'll have numpy 1.15.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: creme 0.4.4 has requirement scikit-learn>=0.21.2, but you'll have scikit-learn 0.20.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: creme 0.4.4 has requirement scipy>=1.3.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: alibi-detect 0.1.0 has requirement tensorflow>=2, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, scipy, pytz, pyparsing, kiwisolver, scikit-learn, python-dateutil, pandas, matplotlib, xai, seldon-core, imageio, networkx, PyWavelets, scikit-image, soupsieve, beautifulsoup4, tensorboard, tensorflow-estimator, tensorflow, alibi, dill\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "  Found existing installation: scipy 1.3.3\n",
      "    Uninstalling scipy-1.3.3:\n",
      "      Successfully uninstalled scipy-1.3.3\n",
      "  Found existing installation: pytz 2019.3\n",
      "    Uninstalling pytz-2019.3:\n",
      "      Successfully uninstalled pytz-2019.3\n",
      "  Found existing installation: pyparsing 2.4.5\n",
      "    Uninstalling pyparsing-2.4.5:\n",
      "      Successfully uninstalled pyparsing-2.4.5\n",
      "  Found existing installation: kiwisolver 1.1.0\n",
      "    Uninstalling kiwisolver-1.1.0:\n",
      "      Successfully uninstalled kiwisolver-1.1.0\n",
      "  Found existing installation: scikit-learn 0.21.3\n",
      "    Uninstalling scikit-learn-0.21.3:\n",
      "      Successfully uninstalled scikit-learn-0.21.3\n",
      "  Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Found existing installation: pandas 1.0.0\n",
      "    Uninstalling pandas-1.0.0:\n",
      "      Successfully uninstalled pandas-1.0.0\n",
      "  Found existing installation: matplotlib 3.1.2\n",
      "    Uninstalling matplotlib-3.1.2:\n",
      "      Successfully uninstalled matplotlib-3.1.2\n",
      "  Found existing installation: seldon-core 1.0.1\n",
      "    Uninstalling seldon-core-1.0.1:\n",
      "      Successfully uninstalled seldon-core-1.0.1\n",
      "  Found existing installation: tensorboard 2.0.1\n",
      "    Uninstalling tensorboard-2.0.1:\n",
      "      Successfully uninstalled tensorboard-2.0.1\n",
      "  Found existing installation: tensorflow-estimator 2.0.1\n",
      "    Uninstalling tensorflow-estimator-2.0.1:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0.1\n",
      "  Found existing installation: tensorflow 2.0.0\n",
      "    Uninstalling tensorflow-2.0.0:\n",
      "      Successfully uninstalled tensorflow-2.0.0\n",
      "Successfully installed PyWavelets-1.1.1 alibi-0.3.2 beautifulsoup4-4.8.2 dill-0.3.1.dev0 imageio-2.8.0 kiwisolver-1.0.1 matplotlib-3.0.2 networkx-2.4 numpy-1.15.4 pandas-0.23.4 pyparsing-2.3.0 python-dateutil-2.7.5 pytz-2018.7 scikit-image-0.16.2 scikit-learn-0.20.1 scipy-1.1.0 seldon-core-0.5.1 soupsieve-2.0 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 xai-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements-dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](../../seldon_core_setup.ipynb#Setup-Cluster) with [Ambassador Ingress](../../seldon_core_setup.ipynb#Ambassador) and [Install Seldon Core](../../seldon_core_setup.ipynb#Install-Seldon-Core). Instructions [also online](./seldon_core_setup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Train a model to predict loan approvals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alibi\n",
    "import numpy as np\n",
    "\n",
    "adult = alibi.datasets.fetch_adult()\n",
    "\n",
    "data = adult.data\n",
    "labels = adult.target\n",
    "feature_names = adult.feature_names\n",
    "category_map = adult.category_map\n",
    "\n",
    "# define train and test set\n",
    "np.random.seed(0)\n",
    "data_perm = np.random.permutation(np.c_[data, labels])\n",
    "data = data_perm[:, :-1]\n",
    "labels = data_perm[:, -1]\n",
    "\n",
    "idx = 30000\n",
    "X_train, y_train = data[:idx, :], labels[:idx]\n",
    "X_test, y_test = data[idx + 1:, :], labels[idx + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# feature transformation pipeline\n",
    "ordinal_features = [x for x in range(len(feature_names)) if x not in list(category_map.keys())]\n",
    "ordinal_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                      ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = list(category_map.keys())\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', ordinal_transformer, ordinal_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('num', Pipeline(memory=None,\n",
       "     steps=[('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan,\n",
       "       strategy='median', verbose=0)), ('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))]), [0, 8, 9, 10]), ('cat', Pipeline(memory=None,\n",
       "     steps=[(...oat64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True))]), [1, 2, 3, 4, 5, 6, 7, 11])])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(0)\n",
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(preprocessor.transform(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.708042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.661765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specificity</th>\n",
       "      <td>0.914271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.853906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.788018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.684122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               target\n",
       "precision    0.708042\n",
       "recall       0.661765\n",
       "specificity  0.914271\n",
       "accuracy     0.853906\n",
       "auc          0.788018\n",
       "f1           0.684122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xai\n",
    "pred = clf.predict(preprocessor.transform(X_test))\n",
    "xai.metrics_plot(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Containerise and deploy your model\n",
    "\n",
    "The steps to cotainerise a model with Seldon are always consistent, and require the following steps:\n",
    "\n",
    "1) Save the model artefacts in the model folder\n",
    "\n",
    "2) Write a wrapper with a `predict` function\n",
    "\n",
    "3) Add the python requirements\n",
    "\n",
    "4) Add the Source2Image configuration so the script knows which Model.py file to use\n",
    "\n",
    "5) Run the s2i command to build the image\n",
    "\n",
    "6) Deploy your image with a Seldon Graph Definition\n",
    "\n",
    "### Once you've deployed it, you are able to test it with Curl or with our Python SeldonClient\n",
    "\n",
    "Let's start containerising it - we'll be using the following folder for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pipeline/pipeline_steps/loanclassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Save the trained model in the folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b71bc5a112fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pipeline/pipeline_steps/loanclassifier/preprocessor.dill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprep_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprep_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pipeline/pipeline_steps/loanclassifier/model.dill\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "with open(\"pipeline/pipeline_steps/loanclassifier/preprocessor.dill\", \"wb\") as prep_f:\n",
    "    dill.dump(preprocessor, prep_f)\n",
    "    \n",
    "with open(\"pipeline/pipeline_steps/loanclassifier/model.dill\", \"wb\") as model_f:\n",
    "    dill.dump(clf, model_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Write a python wrapper for the loan approval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier/Model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier/Model.py\n",
    "import dill\n",
    "import logging\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        with open(\"preprocessor.dill\", \"rb\") as prep_f:\n",
    "            self.preprocessor = dill.load(prep_f)\n",
    "        with open(\"model.dill\", \"rb\") as model_f:\n",
    "            self.clf = dill.load(model_f)\n",
    "        \n",
    "    def predict(self, X, feature_names=[]):\n",
    "        logging.warn(\"Received: \" + str(X))\n",
    "        X_prep = self.preprocessor.transform(X)\n",
    "        proba = self.clf.predict_proba(X_prep)\n",
    "        logging.warn(\"Predicted: \" + str(proba))\n",
    "        return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Add the python requirements for the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier/requirements.txt\n",
    "scikit-learn==0.20.1\n",
    "dill==0.3.1\n",
    "scikit-image==0.15.0\n",
    "scikit-learn==0.20.1\n",
    "scipy==1.1.0\n",
    "numpy==1.15.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Create the source2image configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pipeline/pipeline_steps/loanclassifier/.s2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier/.s2i/environment\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier/.s2i/environment\n",
    "MODEL_NAME=Model\n",
    "API_TYPE=REST\n",
    "SERVICE_TYPE=MODEL\n",
    "PERSISTENCE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 - Now we can build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Looking in links: /whl\n",
      "Collecting scikit-learn==0.20.1 (from -r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/b0/3a/0802b78f697ae04ba06f49d0ebc6e872f2c470687c3e61ad8ef523e125c3/scikit_learn-0.20.1-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting dill==0.3.1 (from -r requirements.txt (line 2))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz (151kB)\n",
      "  WARNING: Requested dill==0.3.1 from https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz#sha256=d3ddddf2806a7bc9858b20c02dc174396795545e9d62f243b34481fd26eb3e2c (from -r requirements.txt (line 2)), but installing version 0.3.1.dev0\n",
      "Collecting scikit-image==0.15.0 (from -r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/2e/21/ea56c8bb2e8112837dd71aebeb2ac67913e784911c0d7f493a593fa1a207/scikit_image-0.15.0-cp37-cp37m-manylinux1_x86_64.whl (26.3MB)\n",
      "Collecting scipy==1.1.0 (from -r requirements.txt (line 5))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/40/de/0c22c6754370ba6b1fa8e53bd6e514d4a41a181125d405a501c215cbdbd6/scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2MB)\n",
      "Collecting numpy==1.15.4 (from -r requirements.txt (line 6))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/38/39/f73e104d44f19a6203e786d5204532e214443ea2954917b27f3229e7639b/numpy-1.15.4-cp37-cp37m-manylinux1_x86_64.whl (13.8MB)\n",
      "Collecting networkx>=2.0 (from scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "Collecting matplotlib!=3.0.0,>=2.0.0 (from scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/6c/ab/e1585a7101f8f7047376b59274ada50fefd637bd4cd99d2125a1b730845a/matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4MB)\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "Collecting imageio>=2.0.1 (from scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
      "Collecting pillow>=4.3.0 (from scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/f5/79/b2d5695d1a931474fa68b68ec93bdf08ba9acbc4d6b3b628eb6aac81d11c/Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting decorator>=4.3.0 (from networkx>=2.0->scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3)) (2.8.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3)) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image==0.15.0->-r requirements.txt (line 3)) (41.4.0)\n",
      "Building wheels for collected packages: dill\n",
      "Building wheel for dill (setup.py): started\n",
      "Building wheel for dill (setup.py): finished with status 'done'\n",
      "Created wheel for dill: filename=dill-0.3.1.dev0-cp37-none-any.whl size=78554 sha256=aeb09938c18110175f46b023dbcf15f93f98bb79bc0c5eeda7804da725c8f327\n",
      "Stored in directory: /root/.cache/pip/wheels/b6/26/8f/152327a2b78a0c2c3166e5d20d331bd4fb1272e810836fed76\n",
      "Successfully built dill\n",
      "Installing collected packages: numpy, scipy, scikit-learn, dill, decorator, networkx, pyparsing, cycler, kiwisolver, matplotlib, PyWavelets, pillow, imageio, scikit-image\n",
      "Found existing installation: numpy 1.18.1\n",
      "Uninstalling numpy-1.18.1:\n",
      "Successfully uninstalled numpy-1.18.1\n",
      "Successfully installed PyWavelets-1.1.1 cycler-0.10.0 decorator-4.4.2 dill-0.3.1.dev0 imageio-2.8.0 kiwisolver-1.1.0 matplotlib-3.2.0 networkx-2.4 numpy-1.15.4 pillow-7.0.0 pyparsing-2.4.6 scikit-image-0.15.0 scikit-learn-0.20.1 scipy-1.1.0\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build pipeline/pipeline_steps/loanclassifier seldonio/seldon-core-s2i-python37:0.18 loanclassifier:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*or* if using Minikube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 - And deploy it to Kubernetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: seldon\n",
    "  name: loanclassifier\n",
    "spec:\n",
    "  name: loanclassifier\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: loanclassifier:0.1\n",
    "          name: model\n",
    "    graph:\n",
    "      children: []\n",
    "      name: model\n",
    "      type: MODEL\n",
    "      endpoint:\n",
    "        type: REST\n",
    "    name: loanclassifier\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/loanclassifier created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\r\n",
      "default-broker-filter-7ffddb5dcc-pdbdt                            1/1     Running   0          6d\r\n",
      "default-broker-ingress-5cfc4c8cbc-dqr82                           1/1     Running   0          6d\r\n",
      "loanclassifier-loanclassifier-0-65f87677f6-bgt8x                  0/2     Running   0          2s\r\n",
      "pingsource-test-ping-sourc-472a7c94-49b9-4996-83d4-1b60c0474tpm   1/1     Running   0          6d\r\n",
      "seldon-controller-manager-5cff67b4f5-frvq6                        1/1     Running   0          3d15h\r\n",
      "sklearn-default-0-b79d4d97d-7hvln                                 2/2     Running   0          3d15h\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that it's deployed we can test it with curl\n",
    "**IMPORTANT:** If you are using minikube (instead of docker desktop) you have to forward the port first with:\n",
    "```\n",
    "kubectl port-forward svc/ambassador 8003:80\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60,  9]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll use the output of the first item:\n",
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"names\":[\"t:0\",\"t:1\"],\"ndarray\":[[0.86,0.14]]},\"meta\":{}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   158  100    67  100    91   2913   3956 --:--:-- --:--:-- --:--:--  6869\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60, 9]]}}' \\\n",
    "    http://localhost:80/seldon/default/loanclassifier/api/v1.0/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we can also test it with the Python SeldonClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:True message:\n",
      "Request:\n",
      "data {\n",
      "  ndarray {\n",
      "    values {\n",
      "      list_value {\n",
      "        values {\n",
      "          number_value: 52.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 4.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 0.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 2.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 8.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 4.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 2.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 0.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 0.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 0.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 60.0\n",
      "        }\n",
      "        values {\n",
      "          number_value: 9.0\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Response:\n",
      "meta {\n",
      "}\n",
      "data {\n",
      "  names: \"t:0\"\n",
      "  names: \"t:1\"\n",
      "  ndarray {\n",
      "    values {\n",
      "      list_value {\n",
      "        values {\n",
      "          number_value: 0.86\n",
      "        }\n",
      "        values {\n",
      "          number_value: 0.14\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "batch = X_test[:1]\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:80\",\n",
    "    deployment_name=\"loanclassifier\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"default\",\n",
    "    transport=\"rest\")\n",
    "\n",
    "client_prediction = sc.predict(data=batch)\n",
    "\n",
    "print(client_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Create an explainer to understand predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "predict_fn = lambda x: clf.predict(preprocessor.transform(x))\n",
    "explainer = AnchorTabular(predict_fn, feature_names, categorical_names=category_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 0\n",
    "class_names = ['<=50K', '>50K']\n",
    "predict_fn(X_test[idx].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27,  4,  4,  2,  1,  4,  4,  0,  0,  0, 44,  9]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Marital Status = Separated AND Sex = Female\n",
      "Precision: 0.96\n",
      "Coverage: 0.11\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "\n",
    "print('Anchor: %s' % (' AND '.join(explanation['names'])))\n",
    "print('Precision: %.2f' % explanation['precision'])\n",
    "print('Coverage: %.2f' % explanation['coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### However we need to explain our remotely deployed model in production\n",
    "\n",
    "For this we can actually create a `predict_remote_fn` that uses our SeldonClient to interact with the production model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.utils import get_data_from_proto\n",
    "\n",
    "def predict_remote_fn(X):\n",
    "    from seldon_core.seldon_client import SeldonClient\n",
    "    from seldon_core.utils import get_data_from_proto\n",
    "    \n",
    "    kwargs = { \n",
    "        \"deployment_name\": \"loanclassifier\",\n",
    "        \"payload_type\": \"ndarray\",\n",
    "        \"namespace\": \"default\",\n",
    "        \"transport\": \"rest\"\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        kwargs[\"gateway_endpoint\"] = \"localhost:80\"\n",
    "        sc = SeldonClient(**kwargs, gateway=\"ambassador\")\n",
    "        prediction = sc.predict(data=X)\n",
    "    except:\n",
    "        # If we are inside the container, we need to reach the ambassador service directly\n",
    "        kwargs[\"gateway_endpoint\"] = \"localhost:8000\"\n",
    "        sc = SeldonClient(**kwargs, gateway=\"seldon\")\n",
    "        prediction = sc.predict(data=X)\n",
    "    \n",
    "    y = get_data_from_proto(prediction.response)\n",
    "    return y\n",
    "\n",
    "# So the anchor is now connected with the remote model\n",
    "explainer = AnchorTabular(predict_remote_fn, feature_names, categorical_names=category_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We train the anchor explainer with the remote model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.fit(X_train, disc_perc=[25, 50, 75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We now can get explanations of the remote model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Marital Status = Separated AND Sex = Female\n",
      "Precision: 0.96\n",
      "Coverage: 0.11\n"
     ]
    }
   ],
   "source": [
    "explanation = explainer.explain(X_test[idx], threshold=0.95)\n",
    "\n",
    "print('Anchor: %s' % (' AND '.join(explanation['names'])))\n",
    "print('Precision: %.2f' % explanation['precision'])\n",
    "print('Coverage: %.2f' % explanation['coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Containerise and deploy your explainer\n",
    "\n",
    "Once again we will follow the same steps to cotainerise a model with Seldon are always consistent, and require the following steps:\n",
    "\n",
    "1) Save the model artefacts in the model folder\n",
    "\n",
    "2) Write a wrapper with a `predict` function\n",
    "\n",
    "3) Add the python requirements\n",
    "\n",
    "4) Add the Source2Image configuration so the script knows which Model.py file to use\n",
    "\n",
    "5) Run the s2i command to build the image\n",
    "\n",
    "6) Deploy your image with a Seldon Graph Definition\n",
    "\n",
    "### Once you've deployed it, you are able to test it with Curl or with our Python SeldonClient\n",
    "\n",
    "Let's start containerising it - we'll be using the following folder for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p pipeline/pipeline_steps/loanclassifier-explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Save the model artefacts in the model folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open(\"pipeline/pipeline_steps/loanclassifier-explainer/explainer.dill\", \"wb\") as x_f:\n",
    "    dill.dump(explainer, x_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Write a wrapper with a `predict` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier-explainer/Explainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier-explainer/Explainer.py\n",
    "import dill\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class Explainer:\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \n",
    "        with open(\"explainer.dill\", \"rb\") as x_f:\n",
    "            self.explainer = dill.load(x_f)\n",
    "        \n",
    "    def predict(self, X, feature_names=[]):\n",
    "        print(\"Received: \" + str(X))\n",
    "        explanation = self.explainer.explain(X)\n",
    "        print(\"Predicted: \" + str(explanation))\n",
    "        return json.dumps(explanation, cls=NumpyEncoder)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (\n",
    "        np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Add the python requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier-explainer/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier-explainer/requirements.txt\n",
    "scikit-learn==0.20.1\n",
    "dill==0.3.1.\n",
    "alibi==0.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Add the Source2Image configuration so the script knows which Model.py file to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir pipeline/pipeline_steps/loanclassifier-explainer/.s2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline/pipeline_steps/loanclassifier-explainer/.s2i/environment\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier-explainer/.s2i/environment\n",
    "MODEL_NAME=Explainer\n",
    "API_TYPE=REST\n",
    "SERVICE_TYPE=MODEL\n",
    "PERSISTENCE=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Run the s2i command to build the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> Installing application source...\n",
      "---> Installing dependencies ...\n",
      "Looking in links: /whl\n",
      "Collecting scikit-learn==0.20.1 (from -r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/b0/3a/0802b78f697ae04ba06f49d0ebc6e872f2c470687c3e61ad8ef523e125c3/scikit_learn-0.20.1-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n",
      "Collecting dill==0.3.1. (from -r requirements.txt (line 2))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz (151kB)\n",
      "  WARNING: Requested dill==0.3.1. from https://files.pythonhosted.org/packages/3e/ad/31932a4e2804897e6fd2f946d53df51dd9b4aa55e152b5404395d00354d1/dill-0.3.1.tar.gz#sha256=d3ddddf2806a7bc9858b20c02dc174396795545e9d62f243b34481fd26eb3e2c (from -r requirements.txt (line 2)), but installing version 0.3.1.dev0\n",
      "Collecting alibi==0.3.2 (from -r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/00/e7/54214fcf84a65339d6c993121da52edea52b56d39e6ec87ad30c755d665a/alibi-0.3.2-py3-none-any.whl (81kB)\n",
      "Collecting scipy>=0.13.3 (from scikit-learn==0.20.1->-r requirements.txt (line 1))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.1->-r requirements.txt (line 1)) (1.18.1)\n",
      "Collecting scikit-image (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/dc/48/454bf836d302465475e02bc0468b879302145b07a005174c409a5b5869c7/scikit_image-0.16.2-cp37-cp37m-manylinux1_x86_64.whl (26.5MB)\n",
      "Collecting pandas (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/df/16/1d75ca33204c2b34a0a9d1fc50567c2c8997ccaa3446dcd828482f3ebc47/pandas-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)\n",
      "Collecting Pillow (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/f5/79/b2d5695d1a931474fa68b68ec93bdf08ba9acbc4d6b3b628eb6aac81d11c/Pillow-7.0.0-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting spacy (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/37/ff/2a7c89f2069173a1ecbccd95d2a23fc42f89045b33f8a71ef57b360a3de4/spacy-2.2.4-cp37-cp37m-manylinux1_x86_64.whl (10.6MB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from alibi==0.3.2->-r requirements.txt (line 3)) (2.22.0)\n",
      "Collecting tensorflow<2.0 (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
      "Collecting beautifulsoup4 (from alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/cb/a1/c698cf319e9cfed6b17376281bd0efc6bfc8465698f54170ef60a485ab5d/beautifulsoup4-4.8.2-py3-none-any.whl (106kB)\n",
      "Collecting matplotlib!=3.0.0,>=2.0.0 (from scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/6c/ab/e1585a7101f8f7047376b59274ada50fefd637bd4cd99d2125a1b730845a/matplotlib-3.2.0-cp37-cp37m-manylinux1_x86_64.whl (12.4MB)\n",
      "Collecting networkx>=2.0 (from scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/41/8f/dd6a8e85946def36e4f2c69c84219af0fa5e832b018c970e92f2ad337e45/networkx-2.4-py3-none-any.whl (1.6MB)\n",
      "Collecting PyWavelets>=0.4.0 (from scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/62/bd/592c7242fdd1218a96431512e77265c50812315ef72570ace85e1cfae298/PyWavelets-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (4.4MB)\n",
      "Collecting imageio>=2.3.0 (from scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/4c/2b/9dd19644f871b10f7e32eb2dbd6b45149c350b4d5f2893e091b882e03ab7/imageio-2.8.0-py3-none-any.whl (3.3MB)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->alibi==0.3.2->-r requirements.txt (line 3)) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->alibi==0.3.2->-r requirements.txt (line 3)) (2.8.1)\n",
      "Collecting wasabi<1.1.0,>=0.4.0 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/21/e1/e4e7b754e6be3a79c400eb766fb34924a6d278c43bb828f94233e0124a21/wasabi-0.6.0-py3-none-any.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/e1/79/6ce05ecf4d50344e29749ea7db7ddf427589228fb8fe89b29718c38c27c5/cymem-2.0.3-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting tqdm<5.0.0,>=4.38.0 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/47/55/fd9170ba08a1a64a18a7f8a18f088037316f2a41be04d2fe6ece5a653e8f/tqdm-4.43.0-py2.py3-none-any.whl (59kB)\n",
      "Collecting plac<1.2.0,>=0.9.6 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/86/85/40b8f66c2dd8f4fd9f09d59b22720cffecf1331e788b8a0cab5bafb353d1/plac-1.1.3-py2.py3-none-any.whl\n",
      "Collecting thinc==7.4.0 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/86/23/2061ed61a37e2385647542eb2be12e7da1fe0cf5c82d154971e5bbafa4ca/thinc-7.4.0-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->alibi==0.3.2->-r requirements.txt (line 3)) (41.4.0)\n",
      "Collecting srsly<1.1.0,>=1.0.2 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/4c/27/0e1deb477dd422427a18d8283b7aacf48b5f77c668feeb2c4920ee6cc3a3/srsly-1.0.2-cp37-cp37m-manylinux1_x86_64.whl (185kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/6c/5b/ae4da6230eb48df353b199f53532c8407d0e9eb6ed678d3d36fa75ac391c/preshed-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (118kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catalogue<1.1.0,>=0.0.7 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/6c/f9/9a5658e2f56932e41eb264941f9a2cb7f3ce41a80cb36b2af6ab78e2f8af/catalogue-1.0.0-py2.py3-none-any.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/73/fc/10eeacb926ec1e88cd62f79d9ac106b0a3e3fe5ff1690422d88c29bd0909/murmurhash-1.0.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting blis<0.5.0,>=0.4.0 (from spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/0a/8c/f1b2aad385de78db151a6e9728026f311dee8bd480f2edc28a0175a543b6/blis-0.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.7MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->alibi==0.3.2->-r requirements.txt (line 3)) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->alibi==0.3.2->-r requirements.txt (line 3)) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->alibi==0.3.2->-r requirements.txt (line 3)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->alibi==0.3.2->-r requirements.txt (line 3)) (2.8)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3)) (0.33.6)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Collecting tensorflow-estimator==1.15.1 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3)) (1.12.0)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/b2/49/2233e63052d5686c72131b579837ddfb98ba9dd0b92bb91efcb441ada8ce/opt_einsum-3.2.0-py3-none-any.whl (63kB)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3)) (1.27.2)\n",
      "Collecting gast==0.2.2 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting wrapt>=1.11.1 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/82/f7/e43cefbe88c5fd371f4cf0cf5eb3feccd07515af9fd6cf7dbf1d1793a797/wrapt-1.12.1.tar.gz\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3)) (3.11.3)\n",
      "Collecting google-pasta>=0.1.6 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl (57kB)\n",
      "Collecting keras-applications>=1.0.8 (from tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "Collecting soupsieve>=1.2 (from beautifulsoup4->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/05/cf/ea245e52f55823f19992447b008bcbb7f78efc5960d77f6c34b5b45b36dd/soupsieve-2.0-py2.py3-none-any.whl\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.0.0,>=2.0.0->scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/5d/bc/1e58593167fade7b544bfe9502a26dc860940a79ab306e651e7f13be68c2/pyparsing-2.4.6-py2.py3-none-any.whl (67kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib!=3.0.0,>=2.0.0->scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/93/f8/518fb0bb89860eea6ff1b96483fbd9236d5ee991485d0f3eceff1770f654/kiwisolver-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (90kB)\n",
      "Collecting decorator>=4.3.0 (from networkx>=2.0->scikit-image->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/ed/1b/72a1821152d07cf1d8b6fce298aeb06a7eb90f4d6d41acec9861e7cc6df0/decorator-4.4.2-py2.py3-none-any.whl\n",
      "Collecting importlib-metadata>=0.20; python_version < \"3.8\" (from catalogue<1.1.0,>=0.0.7->spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://files.pythonhosted.org/packages/8b/03/a00d504808808912751e64ccf414be53c29cad620e3de2421135fcae3025/importlib_metadata-1.5.0-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3)) (1.0.0)\n",
      "Collecting h5py (from keras-applications>=1.0.8->tensorflow<2.0->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->alibi==0.3.2->-r requirements.txt (line 3))\n",
      "  WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Downloading https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
      "Building wheels for collected packages: dill, termcolor, absl-py, gast, wrapt\n",
      "Building wheel for dill (setup.py): started\n",
      "Building wheel for dill (setup.py): finished with status 'done'\n",
      "Created wheel for dill: filename=dill-0.3.1.dev0-cp37-none-any.whl size=78554 sha256=242d5143f997752b491e0f890bd55bd60ad5351ec94651b63542ac115293d147\n",
      "Stored in directory: /root/.cache/pip/wheels/b6/26/8f/152327a2b78a0c2c3166e5d20d331bd4fb1272e810836fed76\n",
      "Building wheel for termcolor (setup.py): started\n",
      "Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4832 sha256=feb5d2759c779284519fa456c0c7a01dfae80a99c6b7cef7e6096ec5c924a04d\n",
      "Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "Building wheel for absl-py (setup.py): started\n",
      "Building wheel for absl-py (setup.py): finished with status 'done'\n",
      "Created wheel for absl-py: filename=absl_py-0.9.0-cp37-none-any.whl size=121932 sha256=cc81dcdd0dec7e6800b94712207cb6797d65b397664cc2503d0fe5f0fa7f85eb\n",
      "Stored in directory: /root/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Building wheel for gast (setup.py): started\n",
      "Building wheel for gast (setup.py): finished with status 'done'\n",
      "Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=94683e29c7bba475e81aac5c7253e062994dc326bfc2daa784a77220e06174c5\n",
      "Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Building wheel for wrapt (setup.py): started\n",
      "Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=76411 sha256=c80ca856a91a61f097da22b6bc2b15943bc94da2891b44312e31c4e1ddefd66b\n",
      "Stored in directory: /root/.cache/pip/wheels/b1/c2/ed/d62208260edbd3fa7156545c00ef966f45f2063d0a84f8208a\n",
      "Successfully built dill termcolor absl-py gast wrapt\n",
      "Installing collected packages: scipy, scikit-learn, dill, cycler, pyparsing, kiwisolver, matplotlib, decorator, networkx, Pillow, PyWavelets, imageio, scikit-image, pandas, wasabi, cymem, tqdm, plac, murmurhash, preshed, srsly, zipp, importlib-metadata, catalogue, blis, thinc, spacy, termcolor, astor, tensorflow-estimator, markdown, absl-py, tensorboard, keras-preprocessing, opt-einsum, gast, wrapt, google-pasta, h5py, keras-applications, tensorflow, soupsieve, beautifulsoup4, alibi\n",
      "Found existing installation: tqdm 4.36.1\n",
      "Uninstalling tqdm-4.36.1:\n",
      "Successfully uninstalled tqdm-4.36.1\n",
      "Successfully installed Pillow-7.0.0 PyWavelets-1.1.1 absl-py-0.9.0 alibi-0.3.2 astor-0.8.1 beautifulsoup4-4.8.2 blis-0.4.1 catalogue-1.0.0 cycler-0.10.0 cymem-2.0.3 decorator-4.4.2 dill-0.3.1.dev0 gast-0.2.2 google-pasta-0.2.0 h5py-2.10.0 imageio-2.8.0 importlib-metadata-1.5.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 kiwisolver-1.1.0 markdown-3.2.1 matplotlib-3.2.0 murmurhash-1.0.2 networkx-2.4 opt-einsum-3.2.0 pandas-1.0.2 plac-1.1.3 preshed-3.0.2 pyparsing-2.4.6 scikit-image-0.16.2 scikit-learn-0.20.1 scipy-1.4.1 soupsieve-2.0 spacy-2.2.4 srsly-1.0.2 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1 termcolor-1.1.0 thinc-7.4.0 tqdm-4.43.0 wasabi-0.6.0 wrapt-1.12.1 zipp-3.1.0\n",
      "WARNING: Url '/whl' is ignored. It is either a non-existing path or lacks a specific scheme.\n",
      "Build completed successfully\n"
     ]
    }
   ],
   "source": [
    "!s2i build pipeline/pipeline_steps/loanclassifier-explainer seldonio/seldon-core-s2i-python37:0.18 loanclassifier-explainer:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*or* if using minikube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "eval $(minikube docker-env)\n",
    "s2i build pipeline/pipeline_steps/loanclassifier-explainer seldonio/seldon-core-s2i-python37:0.18 loanclassifier-explainer:0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Deploy your image with a Seldon Graph Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  labels:\n",
    "    app: seldon\n",
    "  name: loanclassifier\n",
    "spec:\n",
    "  name: loanclassifier\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    - spec:\n",
    "        containers:\n",
    "        - image: loanclassifier:0.1\n",
    "          name: model\n",
    "    graph:\n",
    "      children: []\n",
    "      name: model\n",
    "      type: MODEL\n",
    "      endpoint:\n",
    "        type: REST\n",
    "    explainer:\n",
    "      type: \"AnchorExplainer\"\n",
    "      containerSpec:\n",
    "        name: \"loanclassifier-explainer\"\n",
    "        image: loanclassifier-explainer:0.1\n",
    "    name: loanclassifier\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/loanclassifier created\r\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f pipeline/pipeline_steps/loanclassifier/loanclassifiermodel.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "ambassador-69b784f9d5-242jz                                       1/1     Running   0          9m7s\n",
      "ambassador-69b784f9d5-b2655                                       1/1     Running   0          9m7s\n",
      "ambassador-69b784f9d5-ckrt2                                       1/1     Running   0          9m7s\n",
      "loanclassifier-explainer-loanclassifier-explainer-8444816-fvb8r   2/2     Running   0          33s\n",
      "loanclassifier-loanclassifier-164157f-645c997d57-vqjv4            2/2     Running   0          9m3s\n"
     ]
    }
   ],
   "source": [
    "!kubectl get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that it's deployed we can query it\n",
    "**IMPORTANT:** If you are using minikube (instead of docker desktop) you have to forward the port first with:\n",
    "```\n",
    "kubectl port-forward svc/ambassador 8003:80\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First we can try Curl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"data\":{\"names\":[\"t:0\",\"t:1\"],\"ndarray\":[[0.86,0.14]]},\"meta\":{}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Unnecessary use of -X or --request, POST is already inferred.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying 127.0.0.1...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (127.0.0.1) port 80 (#0)\n",
      "> POST /seldon/default/loanclassifier/api/v1.0/predictions HTTP/1.1\r\n",
      "> Host: localhost\r\n",
      "> User-Agent: curl/7.58.0\r\n",
      "> Accept: */*\r\n",
      "> Content-Type: application/json\r\n",
      "> Content-Length: 91\r\n",
      "> \r\n",
      "} [91 bytes data]\n",
      "* upload completely sent off: 91 out of 91 bytes\n",
      "< HTTP/1.1 200 OK\r\n",
      "< content-type: application/json\r\n",
      "< date: Mon, 16 Mar 2020 14:44:08 GMT\r\n",
      "< content-length: 67\r\n",
      "< x-envoy-upstream-service-time: 12\r\n",
      "< server: istio-envoy\r\n",
      "< \r\n",
      "{ [67 bytes data]\n",
      "\r",
      "100   158  100    67  100    91   3045   4136 --:--:-- --:--:-- --:--:--  7523\n",
      "* Connection #0 to host localhost left intact\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -v -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\": {\"names\": [\"text\"], \"ndarray\": [[52,  4,  0,  2,  8,  4,  2,  0,  0,  0, 60, 9]]}}' \\\n",
    "    http://localhost:80/seldon/default/loanclassifier/api/v1.0/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Test production predictions and explanations\n",
    "\n",
    "We create a seldon client to send requests to the deployed model as well as the explainer. Here is the diagram of the deployed models:\n",
    "\n",
    "![](img/deploy-overview.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SeldonClient(\n",
    "    gateway=\"ambassador\", \n",
    "    gateway_endpoint=\"localhost:8003\",\n",
    "    payload_type=\"ndarray\",\n",
    "    namespace=\"seldon\",\n",
    "    transport=\"rest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look at the datapoint we'll use for this prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52  4  0  2  8  4  2  0  0  0 60  9]]\n"
     ]
    }
   ],
   "source": [
    "to_explain = X_test[:1]\n",
    "print(to_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We get the prediction from the model in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: NEGATIVE\n",
      "Predicted Probabilities: [0.86 0.14]\n"
     ]
    }
   ],
   "source": [
    "resp = sc.predict(data=to_explain, deployment_name=\"loanclassifier\").response\n",
    "pred = get_data_from_proto(resp)\n",
    "print('Predicted Label: %s' % (\"POSITIVE\" if pred[0][0] < 0.5 else \"NEGATIVE\"))\n",
    "print('Predicted Probabilities: %s' % pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By checking our test label, we can see it is indeed correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label: NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "print('Actual Label: %s' % (\"POSITIVE\" if y_test[0] == 1 else \"NEGATIVE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use our deployed explainer to explain our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anchor: Marital Status = Separated AND Sex = Female\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "explanation = sc.predict(data=to_explain, deployment_name=\"loanclassifier-explainer\")\n",
    "exp = json.loads(explanation.response.strData)\n",
    "\n",
    "print('Anchor: %s' % (' AND '.join(exp['names'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
